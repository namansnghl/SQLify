{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ad39232-1329-4f16-813a-e317281f51c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric, concatenate_datasets\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "from transformers import Seq2SeqTrainer\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b93ebbe2-c491-4388-a679-fbfe29a63bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c1bab17-37da-4248-8466-3287b9d86fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla V100-PCIE-32GB'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1633a94e-e4ce-4182-bdf4-f28a3307725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ab46245-d96e-46c6-bfa8-629913346565",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_dataset('wikisql', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b620720-7fdb-48a8-a848-08d8bf2dbad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOK = '[SOS] '\n",
    "def format_dataset(example):\n",
    "    return {'input': START_TOK+example['question'], 'target': example['sql']['human_readable']}\n",
    "\n",
    "test_data = test_data.map(format_dataset, remove_columns=test_data.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19f506e3-fe5a-4e7b-969f-6a0b84438aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER = 2 # start end tokens\n",
    "MAX_LENGTH = 64 + BUFFER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22d94328-060a-4b02-9e67-85e41ae60dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT = 'facebook/bart-base'\n",
    "tokenizer = BartTokenizer.from_pretrained(CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "977835e4-3ef4-43d3-a92a-14d922227e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_features(example_batch):\n",
    "    input_encodings = tokenizer.batch_encode_plus(example_batch['input'], padding='max_length', max_length=MAX_LENGTH, truncation=True)\n",
    "    target_encodings = tokenizer.batch_encode_plus(example_batch['target'], padding='max_length', max_length=MAX_LENGTH, truncation=True)\n",
    "    \n",
    "    encodings = {\n",
    "        'input_ids': input_encodings['input_ids'], \n",
    "        'attention_mask': input_encodings['attention_mask'],\n",
    "        'labels': target_encodings['input_ids'],\n",
    "        'decoder_attention_mask': target_encodings['attention_mask']\n",
    "    }\n",
    "\n",
    "\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "922399d5-65ba-4156-8bf7-4eb399ce503d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f377e4bbe94b5d98aeea24498d221f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/15878 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finaltest_data = test_data.map(convert_to_features, batched=True, remove_columns=test_data.column_names, num_proc=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "334b5305-3ad1-4f62-b6ac-0b328d838800",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']\n",
    "finaltest_data.set_format(type='torch', columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24f3ab05-398b-4ff2-8ede-e26ca1612df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "local = '/home/athani.sh/Model_path'\n",
    "model = BartForConditionalGeneration.from_pretrained(local, device_map=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14873a3b-8863-4227-acfc-c00f9a8e1f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(finaltest_data, batch_size=50, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e242d123-bd3c-4527-bef6-5d256a7dc97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "709185d4-4c82-4d01-9298-ebd31bead020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming testdata is a DataLoader that batches your Dataset\n",
    "total_loss = 0\n",
    "total_bleu = 0\n",
    "\n",
    "with torch.no_grad():  # No need to track gradients in evaluation\n",
    "    for batch in test_dl:\n",
    "        # Send your batch of inputs to the device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        decoder_attention_mask = batch['decoder_attention_mask'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels, decoder_attention_mask=decoder_attention_mask)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Compute BLEU score\n",
    "        predictions = outputs.logits.argmax(-1)  # Get the model's predictions\n",
    "        for prediction, label in zip(predictions, labels):\n",
    "            # Convert tensors to lists\n",
    "            prediction = prediction.tolist()\n",
    "            label = label.tolist()\n",
    "\n",
    "            # Compute the BLEU score between the predicted and actual sentence\n",
    "            bleu_score = sentence_bleu([label], prediction)\n",
    "            total_bleu += bleu_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35d119d1-68ae-4acf-b2fc-59a81cecc580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 0.0019870229531842045, Average BLEU score: 0.9555418548086513\n"
     ]
    }
   ],
   "source": [
    "# Compute the average loss and BLEU score over all the batches\n",
    "avg_loss = total_loss / finaltest_data.shape[0]\n",
    "avg_bleu = total_bleu / finaltest_data.shape[0]\n",
    "\n",
    "print(f'Average loss: {avg_loss}, Average BLEU score: {avg_bleu}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4223d1ec-7947-4659-903f-bb55124d88e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
